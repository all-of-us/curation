version: 2.1

orbs:
  # Send notifications for failed builds on master, develop branches using Slack orb (https://circleci.com/orbs/registry/orb/circleci/slack). Refer to the
  # For channels to notify and webhook URL refer to the CircleCI Slack App page (https://slack.com/apps/A0F7VRE7N-circleci).
  slack: circleci/slack@3.4.2

job_defaults: &job_defaults
    working_directory: ~/curation/data_steward
    parallelism: 1
    shell: /bin/bash --login
    # CircleCI 2.0 does not support environment variables that refer to each other the same way as 1.0 did.
    # If any of these refer to each other, rewrite them so that they don't or see https://circleci.com/docs/2.0/env-vars/#interpolating-environment-variables-to-set-other-environment-variables .
    environment:
      - CIRCLE_ARTIFACTS: /tmp/circleci-artifacts
    docker:
      - image: cimg/python:3.7

commands:
  # Define reusable sets of steps to be run within the testing jobs.
  lint_setup:
    steps:
      - checkout:
          path: ~/curation
      # Dependencies
      - restore_cache:
          keys:
            - pip-cache-{{ checksum "requirements.txt" }}-{{ checksum "dev_requirements.txt" }}-{{ checksum "deid/requirements.txt" }}
            - pip-cache-
      - run:
          working_directory: ~/curation/data_steward
          name: Upgrade pip and install requirements
          command: |
            echo "Installing directly to docker image.  No virtual environment."
            pip install --upgrade pip setuptools
            pip install -r requirements.txt
            pip install -r dev_requirements.txt
            pip install -r deid/requirements.txt
      - run:
          name: Show env variables
          command: env 
  lint_teardown:
    steps:
      - save_cache:
          paths:
            ~/curation_venv
          key: pip-cache-{{ checksum "requirements.txt" }}-{{ checksum "dev_requirements.txt" }}-{{ checksum "deid/requirements.txt" }}
      - slack/status:
          fail_only: true
          only_for_branches: master,develop
  test_setup:
    steps:
      - checkout:
          path: ~/curation
      # Prepare for artifact and test results  collection equivalent to how it was done on 1.0.
      - run: mkdir -p $CIRCLE_ARTIFACTS
      - run:
          name: Install google-cloud-sdk
          command: |
            # don't suppress errors.
            set -e
            # TODO: this is done as there is currently (as of 2021.08.19) no 20.04 release in the google repo for...reasons
            # TODO: parameterize gsdk version and sha
            wget https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-353.0.0-linux-x86_64.tar.gz
            # verify integrity
            echo 94fcb77632fed5b6fa61d1bf6c619cbfceb63f3d95911bfe15e7caa401df81c0 \
              google-cloud-sdk-353.0.0-linux-x86_64.tar.gz | sha256sum --check --status && if [[ "$?" -ne 0 ]]; then exit 1; fi
            # if we get here, assume things are ok and do the following:
            # 1. untar source
            # 2. execute installer
            # 3. cd back to home
            # 4. update components (should help us not have to manually manage sha and wget version)
            tar -xzvf google-cloud-sdk-353.0.0-linux-x86_64.tar.gz \
              && cd ./google-cloud-sdk \
              && ./install.sh --quiet \
              && echo "source $(pwd)/path.bash.inc" >> /home/circleci/.profile \
              && cd .. \
              && ./google-cloud-sdk/bin/gcloud components update --quiet
            # finally, add to path

      # Dependencies
      - restore_cache:
          keys:
          - pip-cache-{{ checksum "requirements.txt" }}-{{ checksum "dev_requirements.txt" }}-{{ checksum "deid/requirements.txt" }}
          - pip-cache-
      - run:
          name: Upgrade pip and install requirements
          command: |
            pip install --upgrade pip setuptools
            pip install -r requirements.txt
            pip install -r dev_requirements.txt
            pip install -r deid/requirements.txt
      - run:
          working_directory: ~/curation/data_steward
          name: Set PYTHONPATH and PYTHONVERSION
          command: |
            echo "PYTHONPATH=$(pwd):${PYENV_ROOT}:${PYTHONPATH}" >> ~/.profile
            cat ~/.profile
            source ~/.profile
      - run:
          name: Show env vars 
          command: env
  test_teardown:
    steps:
      - save_cache:
          paths:
            ~/curation_venv
          key: pip-cache-{{ checksum "requirements.txt" }}-{{ checksum "dev_requirements.txt" }}-{{ checksum "deid/requirements.txt" }}
      - run:
          name: Combine Coverage Results
          working_directory: ~/curation
          command: |
              . tests/combine_coverage.sh
          no_output_timeout: 30s
      # Save test results
      - store_test_results:
          path: ~/curation/tests/results/junit
      # Save artifacts
      - store_artifacts:
          path: ~/curation/tests/results/coverage
          destination: test_results
      - slack/status:
          fail_only: true
          only_for_branches: master,develop

jobs:
  linting_checks:
    <<: *job_defaults
    steps:
      - lint_setup
      - run:
          name: Checking commit messages for Jira tag
          working_directory: ~/curation
          command: tools/validate_commit_message.sh
      - run:
          name: Checking PR title for Jira tag
          working_directory: ~/curation
          command: tools/validate_pr_title.sh
      - run:
          name: Checking Python lint with yapf
          working_directory: ~/curation
          command: tools/yapf_lint.sh
      - run:
          name: Checking Python lint with Pylint
          working _directory: ~/curation
          command: pylint -E data_steward tests
      - lint_teardown

  unit_test:
    <<: *job_defaults
    steps:
      - test_setup
      - run:
          name: Run unit tests
          working_directory: ~/curation
          # TODO: These env vars should not be required to run the unit tests.
          environment:
            BUCKET_NAME_FAKE: curation-fake
            RDR_DATASET_ID: curation_fake_rdr
          command: |
            mkdir -p tests/results/coverage/unit/xml
            mkdir -p tests/results/coverage/unit/html
            # store test results in junit format to allow CircleCI Test Summary reporting
            #  https://circleci.com/docs/2.0/collect-test-data/
            mkdir -p tests/results/junit/unit
            ./tests/run_tests.sh -s unit
          no_output_timeout: 300s
          when:  always
      - test_teardown

  integration_test:
    <<: *job_defaults
    steps:
      - test_setup
      # Setup GCP access and create cloud resources as needed.
      - run:
          name: Activate service account
          command: |
            source /home/circleci/curation/data_steward/google-cloud-sdk/path.bash.inc
            ./ci/activate_creds.sh ${HOME}/gcloud-credentials-key.json
      - run:
          name: Set up environment variables
          command: ./init_env.sh
      - run:
          name: Create buckets and datasets
          command: |
            cd ~/curation/data_steward
            python ./ci/test_setup.py
      - run:
          name: Run integration tests
          working_directory: ~/curation
          command: |
            t=$(git log -1 --pretty=%B)
            # If this gets triggered on develop or master, let it run. Note
            # however that on develop, this job is only triggered nightly.
            # Always run on PRs and on any repo commits that include "all tests".
            if [[ "${CIRCLE_BRANCH}" == "develop" ]] || [[ "${CIRCLE_BRANCH}" == "master" ]] || \
                [[ "$t" == *"all tests"* ]] || [[ -n "${CIRCLE_PULL_REQUEST}" ]] || [[ -n "${CIRCLE_PULL_REQUESTS}" ]];
            then
                mkdir -p tests/results/coverage/integration/xml
                mkdir -p tests/results/coverage/integration/html
                # store test results in junit format to allow CircleCI Test Summary reporting
                #  https://circleci.com/docs/2.0/collect-test-data/
                mkdir -p tests/results/junit/integration
                ./tests/run_tests.sh -s integration
            else
                echo "Skipping integration tests"
            fi
          no_output_timeout: 3000s
      - run:
          name: Delete buckets and datasets
          command: ./ci/teardown.sh
          when: on_success
      - test_teardown

workflows:
  version: 2
  test:
    jobs:
      - linting_checks
      - unit_test
      - integration_test:
          filters:
            branches:
              # This would cause too much noise to run on commit, run nightly
              # instead per below workflow.
              ignore: develop
  nightly:
    triggers:
      - schedule:
          cron: "0 6 * * *" # midnight CST
          filters:
            branches:
              only: develop
    jobs:
      - integration_test
