"""
Developed with Python 2.7

Goals
-----
This program should:
    1. ingest Excel files generated by metrics_over_time
        a. these files should show data quality metrics for
               - each HPO site (as a separate sheet)
               - each table type
           at each of the analysis report screenshots (which
           should be generated weekly)

ASSUMPTIONS
-----------
1. The Excel file generated by metrics_over_time was generated
and formatted properly

2. All of the reports generated by metrics_over_time have the
same tabs
"""

import pandas as pd
import xlrd
import os
import datetime


def load_files(metrics, tab_names):
    """
    Function loads all of the HPO sheets from the files in
        the directory (specified) and puts them in an easily-indexable
        dictionary.

    :param
    metrics (list): names of the reports (on a particular metric, such
        as the number of duplicates) that are going to be analyzed

    tab_names (list): list of lists. each list has all of the HPO sites
        (and other additional tabs, such as the total number of duplicates).
        each sub-list represents the tabs for a particular report. each report
        necessitates its own sub-list because the additional tabs may vary
        from report-to-report. the actual HPO tabs should remain consistent
        between reports despite the DQ metric being investigated.

    :return:
    metric_df_dict (dictionary): dictionary with the following structure
    (key:value pairs are represented)
        a. metric_name (e.g. concept) : dictionary
            b. hpo_name : pandas dataframe
                pandas df has all of the information from the sheet from
                the Excel file
    """
    num_files_indexed = 0
    metric_df_dict = {}

    for metric in metrics:
        try:
            file_name = metrics[num_files_indexed]
            tabs = tab_names[num_files_indexed]
            hpo_dict_for_metric = {}

            for tab in tabs:
                sheet = pd.read_excel(metric, sheet_name=str(tab))

                if sheet.empty:
                    print("WARNING: No {} sheet found in dataframe {}".
                          format(tab, file_name))

                    del metric[num_files_indexed]
                    num_files_indexed -= 1  # skip over the HPO site
                else:
                    hpo_dict_for_metric[tab] = sheet

            metric_name = metric[:-31]  # rid of _hpo_sheets...
            metric_df_dict[metric_name] = hpo_dict_for_metric
            num_files_indexed += 1

        except EnvironmentError as e:
            print(os.strerror(e.errno))

    return metric_df_dict


def iterate_columns(metrics_dfs_dict):
    """
    Function is used to iterate through all of the dataframes
        and find the difference between a column and its immediate-left
        column (which should represent the previous date in which the
        analytics report was run)

    :param
    metric_df_dict (dictionary): dictionary with the following structure
    (key:value pairs are represented)
        a. metric_name (e.g. concept) : dictionary
            b. hpo_name : pandas dataframe
                pandas df has all of the information from the sheet from
                the Excel file

    ASSUMPTIONS:

    """
    metric_change_dict = {}

    for metric_name, tab_dict in metrics_dfs_dict.items():
        tab_change_dict = {}

        for tab, df in tab_dict.items():
            col_list = df.columns.tolist()
            new_df = pd.DataFrame(columns=col_list)
            first_date_encountered = False

            for column in col_list:
                try:
                    datetime.datetime.strptime(column, '%B_%d_%Y')

                    # get a baseline - first col all zeros
                    if not first_date_encountered:
                        col_values_old = df[column]  # Series type

                    col_values_recent = df[column]
                    col_values_new = col_values_recent - col_values_old

                    first_date_encountered = True
                    col_values_old = col_values_recent

                    new_df[column] = col_values_new
                except ValueError:  # not a date column; paste old vals
                    new_df[column] = df[column]

            tab_change_dict[tab] = new_df

        metric_change_dict[metric_name] = tab_change_dict

    return metric_change_dict


def output_to_excel_files(delta_dfs_dict, tab_names):
    """
    Function is used to output the 'delta' dataframes
        into Excel files. The sheets of the Excel files
        should parallel the sheets of the
        hpo_sheets_data_analytics.xlsx files (mostly HPO
        sheets with some aggregate follow-ups).

    :param
    delta_dfs_dict (dictionary): dictionary with the following
    structure (key:value pairs are represented)
        a. metric_name (e.g. concept) : dictionary
            b. hpo_name : pandas dataframe
                pandas df has all of the information from the sheet from
                the Excel file

    tab_names (list): list of lists. each list has all of the HPO sites
        (and other additional tabs, such as the total number of duplicates).
        each sub-list represents the tabs for a particular report. each report
        necessitates its own sub-list because the additional tabs may vary
        from report-to-report. the actual HPO tabs should remain consistent
        between reports despite the DQ metric being investigated.
    """
    num_iterated = 0

    # need to ensure following alphabetical pattern of tab_names
    for metric_name in sorted(delta_dfs_dict.keys()):
        metric = delta_dfs_dict[metric_name]
        tabs_to_iterate = tab_names[num_iterated]

        file_name = metric_name + \
            "_weekly_changes_hpo_sheets.xlsx"

        writer = pd.ExcelWriter(file_name, engine='xlsxwriter')

        # iterating through the output sheets (e.g. HPO sites)
        for tab in tabs_to_iterate:
            df_for_tab = metric[tab]
            df_for_tab.to_excel(writer, sheet_name=tab)

        writer.save()
        num_iterated += 1


# sheets to be analyzed
metric1 = 'concept_hpo_sheets_data_analytics.xlsx'
metric2 = 'duplicates_hpo_sheets_data_analytics.xlsx'
metric3 = 'end_before_begin_hpo_sheets_data_analytics.xlsx'

hpo_sites = xlrd.open_workbook(metric1, on_demand=True).sheet_names()

reports = [metric1, metric2, metric3]
tabs_per_report = []

for report in sorted(reports):
    tab_set = xlrd.open_workbook(report, on_demand=True).sheet_names()
    tabs_per_report.append(tab_set)

all_dfs_dict = load_files(reports, tabs_per_report)
change_dfs_dictionary = iterate_columns(all_dfs_dict)

output_to_excel_files(change_dfs_dictionary, tabs_per_report)
