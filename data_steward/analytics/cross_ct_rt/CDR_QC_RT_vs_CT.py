# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.7.1
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# # QC for Cross CT/RT Dataset Quality Concerns
#
# Quality checks performed on RT and CT datasets for the same CDR.  Meant to
# ensure basic sanity checks exist between the two dataset tiers.
#
# DC-1812

import urllib
import pandas as pd
pd.options.display.max_rows = 120

# + tags=["parameters"]
project_id = ""
rt_dataset = ""
ct_dataset = ""
maximum_age=""
# -

# df will have a summary in the end
df = pd.DataFrame(columns = ['query', 'result']) 

# #  Verify the Same Mapping Values for questionnaire_response_id 
# The values in 'observation.questionnaire_response_id' are re-mapped as part of both
# the controlled tier and registered tier de-identification processes.  We need to ensure
# the values are re-mapped such that if the value exists in one tier, it's corresponding
# record in the other tier uses the same mapping.  We expect for more reponses to exist in the
# controlled tier than in the registered tier, so some null counts will be generated by this check in RT data.
# However, if no matches exist between tiers and only mismatches exist, then a problem occurred
# with the re-mapping algorithm and a data quality fix will need to be applied by curation.  Additionally, if 
# null_in_ct is greater than 0, then a RT row suppression may have been missed.

# +
query = f'''

SELECT 
countif((c.questionnaire_response_id IS NOT NULL AND r.questionnaire_response_id IS NOT NULL) AND c.questionnaire_response_id = r.questionnaire_response_id) AS matches,
countif((c.questionnaire_response_id IS NOT NULL AND r.questionnaire_response_id IS NOT NULL) AND c.questionnaire_response_id != r.questionnaire_response_id) AS mismatches,
countif(c.questionnaire_response_id IS NOT NULL AND r.questionnaire_response_id IS NULL) AS null_in_rt,
countif(c.questionnaire_response_id IS NULL AND r.questionnaire_response_id IS NOT NULL) AS null_in_ct,
countif(c.questionnaire_response_id IS NULL AND r.questionnaire_response_id IS NULL) AS null_in_both,
CASE WHEN
  countif((c.questionnaire_response_id IS NOT NULL AND r.questionnaire_response_id IS NOT NULL) AND c.questionnaire_response_id != r.questionnaire_response_id) > 0 
  THEN 'FAILURE' ELSE 'ok'
END
 as success
FROM `{project_id}.{ct_dataset}.observation` c
FULL OUTER JOIN `{project_id}.{rt_dataset}.observation` r
USING (observation_id)
'''
df1=pd.read_gbq(query, dialect='standard')  


if df1['mismatches'].sum()==0:
 df = df.append({'query' : 'Query1 Verify the Same Mapping Values for questionnaire_response_id', 'result' : 'PASS'},  
                ignore_index = True) 
else:
 df = df.append({'query' : 'Query1 Verify the Same Mapping Values for questionnaire_response_id' , 'result' : ''},  
                ignore_index = True) 
df1
# -

# #  Verify person_ids are mapped the same across tiers
# Person_id should be consistent across registered and controlled tiers.  If the values are not the
# same across tables, an error occurred.  This check should force check these values across all
# tables containing a 'person_id' column.  If the mapping is not consistent, this MAY be caused
# by changes in sandbox dataset usage.

# +
query = f"""

DECLARE person_tables Array<String>;
DECLARE i INT64 DEFAULT 0;

set person_tables = Array(
    SELECT table_name
    FROM `{project_id}.{rt_dataset}.INFORMATION_SCHEMA.COLUMNS`
    where lower(column_name) = 'person_id'
    and not REGEXP_CONTAINS(table_name, r'(?i)(death)|(copy)')

    UNION DISTINCT 

    SELECT table_name
    FROM `{project_id}.{ct_dataset}.INFORMATION_SCHEMA.COLUMNS`
    where lower(column_name) = 'person_id'
    and not REGEXP_CONTAINS(table_name, r'(?i)(death)|(copy)')

);

CREATE TEMP TABLE result(table_name STRING, matches INT64, mismatches INT64, null_in_rt INT64, null_in_ct INT64, null_in_both INT64, success STRING);

LOOP
  SET i = i + 1;
  IF i > ARRAY_LENGTH(person_tables) THEN 
    LEAVE; 
  END IF;
  EXECUTE IMMEDIATE '''
INSERT result
select 
"''' || person_tables[ORDINAL(i)] || '''" as table_name,
countif((c.person_id is not null and r.person_id is not null) and c.person_id = r.person_id) as matches,
countif((c.person_id is not null and r.person_id is not null) and c.person_id != r.person_id) as mismatches,
countif(c.person_id is not null and r.person_id is null) as null_in_rt,
countif(c.person_id is null and r.person_id is not null) as null_in_ct,
countif(c.person_id is null and r.person_id is null) as null_in_both,
CASE WHEN
    countif((c.person_id is not null and r.person_id is not null) and c.person_id != r.person_id) > 0
  THEN 'FAILURE' ELSE 'ok'
END
 as success
FROM `{project_id}.{ct_dataset}.''' || person_tables[ORDINAL(i)] || '''` c
FULL OUTER JOIN `{project_id}.{rt_dataset}.''' || person_tables[ORDINAL(i)] || '''` r
USING (''' || person_tables[ORDINAL(i)] || '''_id) ''';

END LOOP;

SELECT *
FROM result
ORDER BY success, matches;

"""
df1=pd.read_gbq(query, dialect='standard')  


if df1['mismatches'].sum()==0:
 df = df.append({'query' : 'Query2 Verify person_ids are mapped the same across tiers', 'result' : 'PASS'},  
                ignore_index = True) 
else:
 df = df.append({'query' : 'Query2 Verify person_ids are mapped the same across tiers' , 'result' : ''},  
                ignore_index = True) 
df1
# -

# # Verify extension tables are mapped the same across tiers
# This will make sure the src_id matches for all available records in the
# extension tables.  If the success column indicates 'FAILURE', curation
# should investigate because RT and CT are using different mapping schemes.
# This MAY be due to a change in sandbox dataset usage.

# +
query = f"""
DECLARE ext_tables Array<Struct<table_name STRING, column_name STRING>>;
DECLARE i INT64 DEFAULT 0;

set ext_tables = Array(
    with data as (
    SELECT table_name, column_name
    FROM `{project_id}.{rt_dataset}.INFORMATION_SCHEMA.COLUMNS`
    where REGEXP_CONTAINS(table_name, r'(?i)(_ext)')
    AND NOT REGEXP_CONTAINS(column_name, r'(?i)(src_id)|(survey_version_concept_id)')

    UNION DISTINCT 

    SELECT table_name, column_name
    FROM `{project_id}.{ct_dataset}.INFORMATION_SCHEMA.COLUMNS`
    where REGEXP_CONTAINS(table_name, r'(?i)(_ext)')
    AND NOT REGEXP_CONTAINS(column_name, r'(?i)(src_id)|(survey_version_concept_id)')
)
SELECT AS STRUCT table_name, column_name
FROM data
);

CREATE TEMP TABLE result(table_name STRING, matches INT64, mismatches INT64, null_in_rt INT64, null_in_ct INT64, null_in_both INT64, success STRING);

LOOP
  SET i = i + 1;
  IF i > ARRAY_LENGTH(ext_tables) THEN 
    LEAVE; 
  END IF;
  EXECUTE IMMEDIATE '''
INSERT result
select 
"''' || ext_tables[ORDINAL(i)].table_name || '''" as table_name,
countif((c.src_id is not null and r.src_id is not null) and c.src_id = r.src_id) as matches,
countif((c.src_id is not null and r.src_id is not null) and c.src_id != r.src_id) as mismatches,
countif(c.src_id is not null and r.src_id is null) as null_in_rt,
countif(c.src_id is null and r.src_id is not null) as null_in_ct,
countif(c.src_id is null and r.src_id is null) as null_in_both,
CASE WHEN 
  countif((c.src_id is not null and r.src_id is not null) and c.src_id != r.src_id) > 0
  THEN 'FAILURE' ELSE 'ok'
END
 as success
FROM `{project_id}.{ct_dataset}.''' || ext_tables[ORDINAL(i)].table_name || '''` c
FULL OUTER JOIN `{project_id}.{rt_dataset}.''' || ext_tables[ORDINAL(i)].table_name || '''` r
USING (''' || ext_tables[ORDINAL(i)].column_name || ''')''';

END LOOP;

SELECT *
FROM result
ORDER BY success, matches;
"""

df1=pd.read_gbq(query, dialect='standard')  

if df1['mismatches'].sum()==0:
 df = df.append({'query' : 'Query3 Verify extension tables are mapped the same across tiers', 'result' : 'PASS'},  
                ignore_index = True) 
else:
 df = df.append({'query' : 'Query3 Verify extension tables are mapped the same across tiers' , 'result' : ''},  
                ignore_index = True) 
df1
# -

# # Ensure More Data Exists in Controlled Tier
# By the stricter nature of the Registered Tier, more data should exist in the
# Controlled Tier than in the Registered Tier. This check codifies that notion
# that more data should exist in the CT than in the RT.

# +
query = f'''

SELECT
  table_id, 
  c.row_count as controlled_n, 
  r.row_count as registered_n,
CASE WHEN 
(c.row_count >= r.row_count) THEN 0
ELSE 1
END AS Failure
FROM `{project_id}.{ct_dataset}.__TABLES__` c
FULL OUTER JOIN `{project_id}.{rt_dataset}.__TABLES__` r
USING (table_id)

'''
df1=pd.read_gbq(query, dialect='standard')  


if df1['Failure'].sum()==0:
 df = df.append({'query' : 'Query4 Ensure More Data Exists in Controlled Tier', 'result' : 'PASS'},  
                ignore_index = True) 
else:
 df = df.append({'query' : 'Query4 Ensure More Data Exists in Controlled Tier' , 'result' : ''},  
                ignore_index = True) 

df1[df1["Failure"] ==1]
# -

# # Verify All primary keys in RT are available in CT
# This is intended to check a table's primary keys in RT and CT.  We
# expect all primary keys in RT to exist in CT as well.  If any primary key values
# are found in RT but not in CT, this should spark an investigation (Failure=1) as it
# may indicate a missed record suppression in RT.


# +
query = f"""
DECLARE omop_tables Array<Struct<table_name STRING, column_name STRING>>;
DECLARE i INT64 DEFAULT 0;

set omop_tables = Array(
with ext as(
    SELECT table_name, column_name                                                                                                                                                                                
    FROM `{project_id}.{rt_dataset}.INFORMATION_SCHEMA.COLUMNS`
    where REGEXP_CONTAINS(table_name, r'(?i)(_ext)')
    AND NOT REGEXP_CONTAINS(column_name, r'(?i)(src_id)|(survey_version_concept_id)')

    UNION DISTINCT

    SELECT table_name, column_name                                                                                                                                                                                
    FROM `{project_id}.{ct_dataset}.INFORMATION_SCHEMA.COLUMNS`
    where REGEXP_CONTAINS(table_name, r'(?i)(_ext)')
    AND NOT REGEXP_CONTAINS(column_name, r'(?i)(src_id)|(survey_version_concept_id)')
),
omop as (
    SELECT table_name, column_name
    FROM `{project_id}.{rt_dataset}.INFORMATION_SCHEMA.COLUMNS`
    where not REGEXP_CONTAINS(table_name, r'(?i)(_ext)')
    AND NOT REGEXP_CONTAINS(column_name, r'(?i)(src_id)|(survey_version_concept_id)|(cohort)')   

    UNION DISTINCT

    SELECT table_name, column_name
    FROM `{project_id}.{ct_dataset}.INFORMATION_SCHEMA.COLUMNS`
    where not REGEXP_CONTAINS(table_name, r'(?i)(_ext)')
    AND NOT REGEXP_CONTAINS(column_name, r'(?i)(src_id)|(survey_version_concept_id)|(cohort)')   
),
data as(
select o.table_name, o.column_name
from omop o
join ext e 
on o.column_name = e.column_name and o.table_name != e.table_name
where REGEXP_CONTAINS(e.table_name, o.table_name)
order by table_name
)

SELECT AS STRUCT table_name, column_name
FROM data
);

CREATE TEMP TABLE result(table_name STRING, in_rt_but_not_ct INT64, Failure INT64);

LOOP
  SET i = i + 1;
  IF i > ARRAY_LENGTH(omop_tables) THEN 
    LEAVE; 
  END IF;
  EXECUTE IMMEDIATE '''
INSERT result
select 
"''' || omop_tables[ORDINAL(i)].table_name || '''" as table_name,
count(*) as in_rt_but_not_ct,
CASE WHEN 
  count(*) > 0
  THEN 1 ELSE 0
END
 as Failure
FROM `{project_id}.{rt_dataset}.''' || omop_tables[ORDINAL(i)].table_name || '''` r
where ''' || omop_tables[ORDINAL(i)].column_name || ''' not in (
SELECT ''' || omop_tables[ORDINAL(i)].column_name || ''' 
FROM `{project_id}.{ct_dataset}.''' || omop_tables[ORDINAL(i)].table_name || '''`)
''';

END LOOP;

-- success is calculated per table in the temporary table --
SELECT *
FROM result
ORDER BY Failure DESC, table_name;
"""

df1=pd.read_gbq(query, dialect='standard')  


if df1['Failure'].sum()==0:
 df = df.append({'query' : 'Query5 Verify All primary keys in RT are available in CT', 'result' : 'PASS'},  
                ignore_index = True) 
else:
 df = df.append({'query' : 'Query5 Verify All primary keys in RT are available in CT' , 'result' : ''},  
                ignore_index = True) 

df1[df1["Failure"] ==1]

# -

# # Verify All person_ids in RT exist in CT
# Run a check to determine if any person_ids exist in the RT that
# do not exist in the CT.  If this happens, we suspect an error exists.
# This is a signal that something is wrong, it will be hard to determine
# if the issue is with RT or CT code without reviewing the github
# changes between the last known functional CDR and the current
# erroneous CDR.  If count is 0, no issues were encountered.


# +
query = f"""
DECLARE person_tables Array<STRING>;
DECLARE i INT64 DEFAULT 0;

set person_tables = Array(
    SELECT table_name                                                                                                                                                                                
    FROM `{project_id}.{rt_dataset}.INFORMATION_SCHEMA.COLUMNS`
    where lower(column_name) = 'person_id'
);

CREATE TEMP TABLE rt_person_id(person_id INT64);
CREATE TEMP TABLE ct_person_id(person_id INT64);

LOOP
  SET i = i + 1;
  IF i > ARRAY_LENGTH(person_tables) THEN
    LEAVE;
  END IF;
  EXECUTE IMMEDIATE '''
INSERT rt_person_id
SELECT distinct person_id
FROM `{project_id}.{rt_dataset}.''' || person_tables[ORDINAL(i)] || '''`
''';

END LOOP;

set i = 0;
LOOP
  SET i = i + 1;
  IF i > ARRAY_LENGTH(person_tables) THEN
    LEAVE;
  END IF;
  EXECUTE IMMEDIATE '''
INSERT ct_person_id
SELECT distinct person_id
FROM `{project_id}.{ct_dataset}.''' || person_tables[ORDINAL(i)] || '''`
''';

END LOOP;

SELECT distinct count(*) as count_not_pass,
  CASE WHEN count(*) > 0 THEN 'FAILURE' ELSE 'ok' END as success
FROM rt_person_id
WHERE person_id not in (select person_id from ct_person_id);
"""

df1=pd.read_gbq(query, dialect='standard') 


if df1['count_not_pass'].sum()==0:
 df = df.append({'query' : 'Query6 Verify All person_ids in RT exist in CT', 'result' : 'PASS'},  
                ignore_index = True) 
else:
 df = df.append({'query' : 'Query6 Verify All person_ids in RT exist in CT' , 'result' : ''},  
                ignore_index = True) 

df1
# -

# # Verify All person_ids in CT includes expected RT drops
# Ensure everyone dropped in RT for max age is as old or older than
# the current threshold age of 'maximum_age' (89 years old).  If someone is dropped
# from the RT and they are not removed by the age requirement,
# something may be wrong.


# +
query = f"""
DECLARE person_tables Array<STRING>;
DECLARE i INT64 DEFAULT 0;

set person_tables = Array(
    SELECT table_name                                                                                                                                                                                
    FROM `{project_id}.{rt_dataset}.INFORMATION_SCHEMA.COLUMNS`
    where lower(column_name) = 'person_id'
);

CREATE TEMP TABLE rt_person_id(person_id INT64);
CREATE TEMP TABLE ct_person_id(person_id INT64);

LOOP
  SET i = i + 1;
  IF i > ARRAY_LENGTH(person_tables) THEN
    LEAVE;
  END IF;
  EXECUTE IMMEDIATE '''
INSERT rt_person_id
SELECT distinct person_id
FROM `{project_id}.{rt_dataset}.''' || person_tables[ORDINAL(i)] || '''`
''';

END LOOP;

set i = 0;
LOOP
  SET i = i + 1;
  IF i > ARRAY_LENGTH(person_tables) THEN
    LEAVE;
  END IF;
  EXECUTE IMMEDIATE '''
INSERT ct_person_id
SELECT distinct person_id
FROM `{project_id}.{ct_dataset}.''' || person_tables[ORDINAL(i)] || '''`
''';

END LOOP;

SELECT distinct person_id,
(2021 - year_of_birth) as age,
CASE WHEN (2021 - year_of_birth) < {maximum_age} THEN 1 ELSE 0 END as Failure
FROM ct_person_id
join `{project_id}.{ct_dataset}.person`
using (person_id)
WHERE person_id not in (select distinct person_id from rt_person_id)
ORDER BY age;
"""

df1=pd.read_gbq(query, dialect='standard')  


if df1['Failure'].sum()==0:
 df = df.append({'query' : 'Query7 Verify All person_ids in CT includes expected RT drops', 'result' : 'PASS'},  
                ignore_index = True) 
else:
 df = df.append({'query' : 'Query7 Verify All person_ids in CT includes expected RT drops' , 'result' : ''},  
                ignore_index = True) 



df1[df1["Failure"] ==1]

# -

# # Summary_CDR_QC_RT_vs_CT_comparison

# if not pass, will be highlighted in red
df = df.mask(df.isin(['Null','']))
df.style.highlight_null(null_color='red').set_properties(**{'text-align': 'left'})
