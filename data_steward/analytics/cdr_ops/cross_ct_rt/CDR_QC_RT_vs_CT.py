# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.7.1
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# # QC for Cross CT/RT Dataset Quality Concerns
#
# Quality checks performed on RT AND CT datasets for the same CDR.  Meant to
# ensure basic sanity checks exist between the two dataset tiers.

# + tags=["parameters"]
project_id = ""
rt_dataset = ""
ct_dataset = ""
maximum_age = ""
run_as = ""

# +
import pandas as pd
from IPython.display import display

from analytics.cdr_ops.notebook_utils import execute, IMPERSONATION_SCOPES
from common import JINJA_ENV, PIPELINE_TABLES
from gcloud.bq import BigQueryClient
from utils import auth

impersonation_creds = auth.get_impersonation_credentials(
    run_as, target_scopes=IMPERSONATION_SCOPES)

client = BigQueryClient(project_id, credentials=impersonation_creds)

pd.options.display.max_rows = 120
# -

# df will have a summary in the end
df = pd.DataFrame(columns=['query', 'result'])

# # Query1: Verify the Same Mapping Values for questionnaire_response_id
# The values in 'observation.questionnaire_response_id' are re-mapped AS part of both
# the controlled tier AND registered tier de-identification processes.  We need to ensure
# the values are re-mapped such that if the value exists in one tier, it's corresponding
# record in the other tier uses the same mapping.  We expect for more reponses to exist in the
# controlled tier than in the registered tier, so some null counts will be generated by this check in RT data.
# However, if no matches exist between tiers AND only mismatches exist, then a problem occurred
# WITH the re-mapping algorithm AND a data quality fix will need to be applied by curation.  Additionally, if
# null_in_ct is greater than 0, then a RT row suppression may have been missed.

# +
query = JINJA_ENV.from_string("""



SELECT 
countif((c.questionnaire_response_id IS NOT NULL AND r.questionnaire_response_id IS NOT NULL) AND c.questionnaire_response_id = r.questionnaire_response_id) AS matches,
countif((c.questionnaire_response_id IS NOT NULL AND r.questionnaire_response_id IS NOT NULL) AND c.questionnaire_response_id != r.questionnaire_response_id) AS mismatches,
countif(c.questionnaire_response_id IS NOT NULL AND r.questionnaire_response_id IS NULL) AS null_in_rt,
countif(c.questionnaire_response_id IS NULL AND r.questionnaire_response_id IS NOT NULL) AS null_in_ct,
countif(c.questionnaire_response_id IS NULL AND r.questionnaire_response_id IS NULL) AS null_in_both,
CASE WHEN
  countif((c.questionnaire_response_id IS NOT NULL AND r.questionnaire_response_id IS NOT NULL) AND c.questionnaire_response_id != r.questionnaire_response_id) > 0 
  THEN 'FAILURE' ELSE 'ok'
END
 AS success
FROM `{{project_id}}.{{ct_dataset}}.observation` c
FULL OUTER JOIN `{{project_id}}.{{rt_dataset}}.observation` r
USING (observation_id);


""")

q = query.render(project_id=project_id,
                 rt_dataset=rt_dataset,
                 ct_dataset=ct_dataset)

df1 = execute(client, q)

if df1['mismatches'].sum() == 0:
    df = df.append(
        {
            'query':
                'Query1 Verify the Same Mapping Values for questionnaire_response_id',
            'result':
                'PASS'
        },
        ignore_index=True)
else:
    df = df.append(
        {
            'query':
                'Query1 Verify the Same Mapping Values for questionnaire_response_id',
            'result':
                ''
        },
        ignore_index=True)
df1

# -

# # Query2: Verify person_ids are mapped the same across tiers
# Person_id should be consistent across registered AND controlled tiers.  If the values are not the
# same across tables, an error occurred.  This check should force check these values across all
# tables containing a 'person_id' column.  If the mapping is not consistent, this MAY be caused
# by changes in sandbox dataset usage.

# +
query = JINJA_ENV.from_string("""
DECLARE person_tables Array<String>;
DECLARE i INT64 DEFAULT 0;

SET person_tables = Array(
    SELECT table_name
    FROM `{{project_id}}.{{rt_dataset}}.INFORMATION_SCHEMA.COLUMNS`
    where lower(column_name) = 'person_id'
    AND not REGEXP_CONTAINS(table_name, r'(?i)(death)|(copy)')

    UNION DISTINCT 

    SELECT table_name
    FROM `{{project_id}}.{{ct_dataset}}.INFORMATION_SCHEMA.COLUMNS`
    where lower(column_name) = 'person_id'
    AND not REGEXP_CONTAINS(table_name, r'(?i)(death)|(copy)')

);

CREATE TEMP TABLE result(table_name STRING, matches INT64, mismatches INT64, null_in_rt INT64, null_in_ct INT64, null_in_both INT64, success STRING);

LOOP
  SET i = i + 1;
  IF i > ARRAY_LENGTH(person_tables) THEN 
    LEAVE; 
  END IF;
  EXECUTE IMMEDIATE '''
INSERT result
SELECT
"''' || person_tables[ORDINAL(i)] || '''" AS table_name,
countif((c.person_id IS NOT NULL AND r.person_id IS NOT NULL) AND c.person_id = r.person_id) AS matches,
countif((c.person_id IS NOT NULL AND r.person_id IS NOT NULL) AND c.person_id != r.person_id) AS mismatches,
countif(c.person_id IS NOT NULL AND r.person_id IS NULL) AS null_in_rt,
countif(c.person_id IS NULL AND r.person_id IS NOT NULL) AS null_in_ct,
countif(c.person_id IS NULL AND r.person_id IS NULL) AS null_in_both,
CASE WHEN
    countif((c.person_id IS NOT NULL AND r.person_id IS NOT NULL) AND c.person_id != r.person_id) > 0
  THEN 'FAILURE' ELSE 'ok'
END
 AS success
FROM `{{project_id}}.{{ct_dataset}}.''' || person_tables[ORDINAL(i)] || '''` c
FULL OUTER JOIN `{{project_id}}.{{rt_dataset}}.''' || person_tables[ORDINAL(i)] || '''` r
USING (''' || person_tables[ORDINAL(i)] || '''_id) ''';

END LOOP;

SELECT *
FROM result
ORDER BY success, matches;
""")

q = query.render(project_id=project_id,
                 rt_dataset=rt_dataset,
                 ct_dataset=ct_dataset)

df1 = execute(client, q)

if df1['mismatches'].sum() == 0:
    df = df.append(
        {
            'query':
                'Query2 Verify person_ids are mapped the same across tiers',
            'result':
                'PASS'
        },
        ignore_index=True)
else:
    df = df.append(
        {
            'query':
                'Query2 Verify person_ids are mapped the same across tiers',
            'result':
                ''
        },
        ignore_index=True)
df1
# -

# # Query3: Verify extension tables are mapped the same across tiers
# This will make sure the src_id matches for all available records in the
# extension tables.  If the success column indicates 'FAILURE', curation
# should investigate because RT AND CT are USING different mapping schemes.
# This MAY be due to a change in sandbox dataset usage.

# +
query = JINJA_ENV.from_string("""
DECLARE ext_tables Array<Struct<table_name STRING, column_name STRING>>;
DECLARE i INT64 DEFAULT 0;

SET ext_tables = Array(
    WITH data AS (
    SELECT table_name, column_name
    FROM `{{project_id}}.{{rt_dataset}}.INFORMATION_SCHEMA.COLUMNS`
    where REGEXP_CONTAINS(table_name, r'(?i)(_ext)')
    AND NOT REGEXP_CONTAINS(column_name, r'(?i)(src_id)|(survey_version_concept_id)|(language)')

    UNION DISTINCT 

    SELECT table_name, column_name
    FROM `{{project_id}}.{{ct_dataset}}.INFORMATION_SCHEMA.COLUMNS`
    where REGEXP_CONTAINS(table_name, r'(?i)(_ext)')
    AND NOT REGEXP_CONTAINS(column_name, r'(?i)(src_id)|(survey_version_concept_id)|(language)')
)
SELECT AS STRUCT table_name, column_name
FROM data
);

CREATE TEMP TABLE result(table_name STRING, matches INT64, mismatches INT64, null_in_rt INT64, null_in_ct INT64, null_in_both INT64, success STRING);

LOOP
  SET i = i + 1;
  IF i > ARRAY_LENGTH(ext_tables) THEN 
    LEAVE; 
  END IF;
  EXECUTE IMMEDIATE '''
INSERT result
SELECT 
"''' || ext_tables[ORDINAL(i)].table_name || '''" AS table_name,
countif((c.src_id IS NOT NULL AND r.src_id IS NOT NULL) AND c.src_id = r.src_id) AS matches,
countif((c.src_id IS NOT NULL AND r.src_id IS NOT NULL) AND c.src_id != r.src_id) AS mismatches,
countif(c.src_id IS NOT NULL AND r.src_id IS NULL) AS null_in_rt,
countif(c.src_id IS NULL AND r.src_id IS NOT NULL) AS null_in_ct,
countif(c.src_id IS NULL AND r.src_id IS NULL) AS null_in_both,
CASE WHEN 
  countif((c.src_id IS NOT NULL AND r.src_id IS NOT NULL) AND c.src_id != r.src_id) > 0
  THEN 'FAILURE' ELSE 'ok'
END
 AS success
FROM `{{project_id}}.{{ct_dataset}}.''' || ext_tables[ORDINAL(i)].table_name || '''` c
FULL OUTER JOIN `{{project_id}}.{{rt_dataset}}.''' || ext_tables[ORDINAL(i)].table_name || '''` r
USING (''' || ext_tables[ORDINAL(i)].column_name || ''')''';

END LOOP;

SELECT *
FROM result
ORDER BY success, matches;
""")

q = query.render(project_id=project_id,
                 rt_dataset=rt_dataset,
                 ct_dataset=ct_dataset)

df1 = execute(client, q)

if df1['mismatches'].sum() == 0:
    df = df.append(
        {
            'query':
                'Query3 Verify extension tables are mapped the same across tiers',
            'result':
                'PASS'
        },
        ignore_index=True)
else:
    df = df.append(
        {
            'query':
                'Query3 Verify extension tables are mapped the same across tiers',
            'result':
                ''
        },
        ignore_index=True)
df1
# -

# # Query4: Ensure More Data Exists in Controlled Tier
# By the stricter nature of the Registered Tier, more data should exist in the
# Controlled Tier than in the Registered Tier. This check codifies that notion
# that more data should exist in the CT than in the RT.

# +
query = JINJA_ENV.from_string("""
SELECT
  table_id, 
  c.row_count AS controlled_n, 
  r.row_count AS registered_n,
CASE WHEN 
(c.row_count >= r.row_count) THEN 0
ELSE 1
END AS Failure
FROM `{{project_id}}.{{ct_dataset}}.__TABLES__` c
FULL OUTER JOIN `{{project_id}}.{{rt_dataset}}.__TABLES__` r
USING (table_id)
""")

q = query.render(project_id=project_id,
                 rt_dataset=rt_dataset,
                 ct_dataset=ct_dataset)

df1 = execute(client, q)

if df1['Failure'].sum() == 0:
    df = df.append(
        {
            'query': 'Query4 Ensure More Data Exists in Controlled Tier',
            'result': 'PASS'
        },
        ignore_index=True)
else:
    df = df.append(
        {
            'query': 'Query4 Ensure More Data Exists in Controlled Tier',
            'result': ''
        },
        ignore_index=True)

df1[df1["Failure"] == 1]
# -

# # Query5: Verify All primary keys in RT are available in CT
# This is intended to check a table's primary keys in RT AND CT.  We
# expect all primary keys in RT to exist in CT AS well.  If any primary key values
# are found in RT but NOT IN CT, this should spark an investigation AS it
# may indicate a missed record suppression in RT.

# +
query = JINJA_ENV.from_string("""
DECLARE omop_tables Array<Struct<table_name STRING, column_name STRING>>;
DECLARE i INT64 DEFAULT 0;

SET omop_tables = Array(
WITH ext AS (
    SELECT table_name, column_name                                                                                                                                                                                
    FROM `{{project_id}}.{{rt_dataset}}.INFORMATION_SCHEMA.COLUMNS`
    WHERE REGEXP_CONTAINS(table_name, r'(?i)(_ext)')
    AND NOT REGEXP_CONTAINS(column_name, r'(?i)(src_id)|(survey_version_concept_id)')

    UNION DISTINCT

    SELECT table_name, column_name                                                                                                                                                                                
    FROM `{{project_id}}.{{ct_dataset}}.INFORMATION_SCHEMA.COLUMNS`
    WHERE REGEXP_CONTAINS(table_name, r'(?i)(_ext)')
    AND NOT REGEXP_CONTAINS(column_name, r'(?i)(src_id)|(survey_version_concept_id)')
),
omop AS (
    SELECT table_name, column_name
    FROM `{{project_id}}.{{rt_dataset}}.INFORMATION_SCHEMA.COLUMNS`
    WHERE not REGEXP_CONTAINS(table_name, r'(?i)(_ext)')
    AND NOT REGEXP_CONTAINS(column_name, r'(?i)(src_id)|(survey_version_concept_id)|(cohort)')   

    UNION DISTINCT

    SELECT table_name, column_name
    FROM `{{project_id}}.{{ct_dataset}}.INFORMATION_SCHEMA.COLUMNS`
    WHERE not REGEXP_CONTAINS(table_name, r'(?i)(_ext)')
    AND NOT REGEXP_CONTAINS(column_name, r'(?i)(src_id)|(survey_version_concept_id)|(cohort)')   
),
data AS (
SELECT o.table_name, o.column_name
FROM omop o
JOIN ext e 
ON o.column_name = e.column_name AND o.table_name != e.table_name
WHERE REGEXP_CONTAINS(e.table_name, o.table_name)
ORDER by table_name
)

SELECT AS STRUCT table_name, column_name
FROM data
);

CREATE TEMP TABLE result(table_name STRING, in_rt_but_not_ct INT64, Failure INT64);

LOOP
  SET i = i + 1;
  IF i > ARRAY_LENGTH(omop_tables) THEN 
    LEAVE; 
  END IF;
  EXECUTE IMMEDIATE '''
INSERT result
SELECT 
"''' || omop_tables[ORDINAL(i)].table_name || '''" AS table_name,
COUNT(*) AS in_rt_but_not_ct,
CASE WHEN 
  COUNT(*) > 0
  THEN 1 ELSE 0
END
 AS Failure
FROM `{{project_id}}.{{rt_dataset}}.''' || omop_tables[ORDINAL(i)].table_name || '''` r
WHERE ''' || omop_tables[ORDINAL(i)].column_name || ''' NOT IN (
SELECT ''' || omop_tables[ORDINAL(i)].column_name || ''' 
FROM `{{project_id}}.{{ct_dataset}}.''' || omop_tables[ORDINAL(i)].table_name || '''`)
''';

END LOOP;

-- success is calculated per table in the temporary table --
SELECT *
FROM result
ORDER BY Failure DESC, table_name;
""")

q = query.render(project_id=project_id,
                 rt_dataset=rt_dataset,
                 ct_dataset=ct_dataset)

df1 = execute(client, q)

if df1['Failure'].sum() == 0:
    df = df.append(
        {
            'query': 'Query5 Verify All primary keys in RT are available in CT',
            'result': 'PASS'
        },
        ignore_index=True)
else:
    df = df.append(
        {
            'query': 'Query5 Verify All primary keys in RT are available in CT',
            'result': ''
        },
        ignore_index=True)

df1[df1["Failure"] == 1]

# -

# # Query6: Verify All person_ids in RT exist in CT
# Run a check to determine if any person_ids exist in the RT that
# do not exist in the CT.  If this happens, we suspect an error exists.
# This is a signal that something is wrong, it will be hard to determine
# if the issue is WITH RT or CT code without reviewing the github
# changes between the last known functional CDR AND the current
# erroneous CDR.  If count is 0, no issues were encountered.

# +
query = JINJA_ENV.from_string("""
DECLARE person_tables Array<STRING>;
DECLARE i INT64 DEFAULT 0;

SET person_tables = Array(
    SELECT table_name                                                                                                                                                                                
    FROM `{{project_id}}.{{rt_dataset}}.INFORMATION_SCHEMA.COLUMNS`
    where lower(column_name) = 'person_id'
);

CREATE TEMP TABLE rt_person_id(person_id INT64);
CREATE TEMP TABLE ct_person_id(person_id INT64);

LOOP
  SET i = i + 1;
  IF i > ARRAY_LENGTH(person_tables) THEN
    LEAVE;
  END IF;
  EXECUTE IMMEDIATE '''
INSERT rt_person_id
SELECT DISTINCT person_id
FROM `{{project_id}}.{{rt_dataset}}.''' || person_tables[ORDINAL(i)] || '''`
WHERE person_id NOT IN (SELECT DISTINCT person_id FROM rt_person_id)
''';

END LOOP;

SET i = 0;
LOOP
  SET i = i + 1;
  IF i > ARRAY_LENGTH(person_tables) THEN
    LEAVE;
  END IF;
  EXECUTE IMMEDIATE '''
INSERT ct_person_id
SELECT DISTINCT person_id
FROM `{{project_id}}.{{ct_dataset}}.''' || person_tables[ORDINAL(i)] || '''`
WHERE person_id NOT IN (SELECT DISTINCT person_id FROM ct_person_id)
''';

END LOOP;

SELECT DISTINCT COUNT(*) AS count_not_pass,
  CASE WHEN COUNT(*) > 0 THEN 'FAILURE' ELSE 'ok' END AS success
FROM rt_person_id
WHERE person_id NOT IN (SELECT DISTINCT person_id FROM ct_person_id);
""")

q = query.render(project_id=project_id,
                 rt_dataset=rt_dataset,
                 ct_dataset=ct_dataset)

df1 = execute(client, q)

if df1['count_not_pass'].sum() == 0:
    df = df.append(
        {
            'query': 'Query6 Verify All person_ids in RT exist in CT',
            'result': 'PASS'
        },
        ignore_index=True)
else:
    df = df.append(
        {
            'query': 'Query6 Verify All person_ids in RT exist in CT',
            'result': ''
        },
        ignore_index=True)

df1
# -

# # Query7: Verify All person_ids in CT includes expected RT drops
# Ensure everyone dropped in RT for max age is AS old or older than
# the current threshold age of 89 years old.  If someone is dropped
# FROM the RT AND they are not removed by the age requirement,
# something may be wrong.

# +
query = JINJA_ENV.from_string("""
DECLARE person_tables Array<STRING>;
DECLARE i INT64 DEFAULT 0;

SET person_tables = Array(
    SELECT table_name                                                                                                                                                                                
    FROM `{{project_id}}.{{rt_dataset}}.INFORMATION_SCHEMA.COLUMNS`
    where lower(column_name) = 'person_id'
);

CREATE TEMP TABLE rt_person_id(person_id INT64);
CREATE TEMP TABLE ct_person_id(person_id INT64);

LOOP
  SET i = i + 1;
  IF i > ARRAY_LENGTH(person_tables) THEN
    LEAVE;
  END IF;
  EXECUTE IMMEDIATE '''
INSERT rt_person_id
SELECT DISTINCT person_id
FROM `{{project_id}}.{{rt_dataset}}.''' || person_tables[ORDINAL(i)] || '''`
WHERE person_id NOT IN (SELECT DISTINCT person_id FROM rt_person_id)
''';

END LOOP;

set i = 0;
LOOP
  SET i = i + 1;
  IF i > ARRAY_LENGTH(person_tables) THEN
    LEAVE;
  END IF;
  EXECUTE IMMEDIATE '''
INSERT ct_person_id
SELECT DISTINCT person_id
FROM `{{project_id}}.{{ct_dataset}}.''' || person_tables[ORDINAL(i)] || '''`
WHERE person_id NOT IN (SELECT DISTINCT person_id FROM ct_person_id)
''';

END LOOP;

SELECT DISTINCT person_id,
{{PIPELINE_TABLES}}.calculate_age(CURRENT_DATE, birth_datetime) AS age,
CASE WHEN {{PIPELINE_TABLES}}.calculate_age(CURRENT_DATE, birth_datetime) < {{maximum_age}}
    THEN 1 ELSE 0 END AS Failure
FROM ct_person_id
JOIN `{{project_id}}.{{ct_dataset}}.person`
USING (person_id)
WHERE person_id NOT IN (SELECT DISTINCT person_id FROM rt_person_id)
ORDER BY age;
""")

q = query.render(project_id=project_id,
                 rt_dataset=rt_dataset,
                 ct_dataset=ct_dataset,
                 PIPELINE_TABLES=PIPELINE_TABLES,
                 maximum_age=maximum_age)

df1 = execute(client, q)

if df1['Failure'].sum() == 0:
    df = df.append(
        {
            'query':
                'Query7 Verify All person_ids in CT includes expected RT drops',
            'result':
                'PASS'
        },
        ignore_index=True)
else:
    df = df.append(
        {
            'query':
                'Query7 Verify All person_ids in CT includes expected RT drops',
            'result':
                ''
        },
        ignore_index=True)

df1[df1["Failure"] == 1]

# -

# # Query8: Verify the wear_study dateshift
#
# RT dates should have been shifted back by the number of days designated to each 
# participant via the primary_pid_rid_mapping table.
#
# The following query will find any rows in the wear_study tables where the RT date plus the date shift is not equal to the 
# CT date. If there are resulting rows, make sure the pipeline dateshift ran properly.

# +
query = JINJA_ENV.from_string("""

SELECT
 'date shift is off' as issue,
 COUNT(*) as bad_rows
FROM
  `{{project_id}}.{{rt_dataset}}.wear_study` rtws
JOIN
  `{{project_id}}.{{ct_dataset}}.wear_study` ctws
USING(person_id)
JOIN
  `{{project_id}}.{{pipeline_tables}}.primary_pid_rid_mapping` pprm
ON rtws.person_id = pprm.research_id
WHERE DATE_ADD(rtws.wear_consent_start_date, INTERVAL shift DAY) <> ctws.wear_consent_start_date
OR DATE_ADD(rtws.wear_consent_end_date, INTERVAL shift DAY) <> ctws.wear_consent_end_date
""")

q = query.render(project_id=project_id,
                 rt_dataset=rt_dataset,
                 ct_dataset=ct_dataset,
                 pipeline_tables=PIPELINE_TABLES)

df1 = execute(client, q)

if df1['bad_rows'].sum() == 0:
    df = df.append(
        {
            'query':
                'Query8 Wear_study dates are as expected.',
            'result':
                'PASS'
        },
        ignore_index=True)
else:
    df = df.append(
        {
            'query':
                'Query8 Wear_study dates are not aligned properly. See description.',
            'result':
                'FAIL'
        },
        ignore_index=True
                  )
    display(df1)
# -

# # Summary_CDR_QC_RT_vs_CT_comparison

# if not pass, will be highlighted in red
df = df.mask(df.isin(['Null', '']))
df.style.highlight_null(null_color='red').set_properties(
    **{'text-align': 'left'})
